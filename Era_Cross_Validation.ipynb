{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Era Cross Validation",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOVt6BcQTmzMxZk6M6Pzq7d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djliden/numerai/blob/main/Era_Cross_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWja9Z7vYnaA"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "[Jump Straight to Cross Validation Section](https://colab.research.google.com/drive/19HnPt-IMBan4uddMjfM2RLO8f9YkSCHP#scrollTo=dFwt8jJvaRWW&line=7&uniqifier=1)\n",
        "\n",
        "This notebook introduces an era-wise cross-validation scheme. Conceptually, it works as follows:\n",
        "\n",
        "1. The class is initialized with the `era` column of the training data (which includes the labeled `validation` data in this example)\n",
        "2. The user decides the number of training eras to include (\"N\"), the number of eras to validate on (\"M\"), and the first validation era (\"X\"). The indices for all observations in the M eras in and following X are returned as the test set; the indices for all observations in the N eras preceding X are returned as the training set.\n",
        "\n",
        "# Setup\n",
        "We run through the setup without documenting our steps. See my `Numerai Starter Kit` notebook for details about these steps: [![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/djliden/numerai_starter_kit/blob/main/Numerai_Starter_Kit.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGyb0eNAZ5nK"
      },
      "source": [
        "## Imports, installations, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch1cyXpSYgLu"
      },
      "source": [
        "%%capture\n",
        "# install\n",
        "!pip install --upgrade python-dotenv numerapi\n",
        "\n",
        "# import dependencies\n",
        "import gc\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from getpass import getpass\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numerapi\n",
        "from pathlib import Path\n",
        "from scipy.stats import spearmanr\n",
        "import sklearn.linear_model\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAi7dhSdaAdQ"
      },
      "source": [
        "## NumerAPI setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lSLmu53aBg7",
        "outputId": "e3c1727b-77ec-443f-c3ef-e1496b4cc7e0"
      },
      "source": [
        "# Load the numerapi credentials from .env or prompt for them if not available\n",
        "def credential():\n",
        "    dotenv_path = find_dotenv()\n",
        "    load_dotenv(dotenv_path)\n",
        "\n",
        "    if os.getenv(\"NUMERAI_PUBLIC_KEY\"):\n",
        "        print(\"Loaded Numerai Public Key into Global Environment!\")\n",
        "    else:\n",
        "        os.environ[\"NUMERAI_PUBLIC_KEY\"] = getpass(\"Please enter your Numerai Public Key. You can find your key here: https://numer.ai/submit -> \")\n",
        "    \n",
        "    if os.getenv(\"NUMERAI_SECRET_KEY\"):\n",
        "        print(\"Loaded Numerai Secret Key into Global Environment!\")\n",
        "    else:\n",
        "        os.environ[\"NUMERAI_SECRET_KEY\"] = getpass(\"Please enter your Numerai Secret Key. You can find your key here: https://numer.ai/submit -> \")\n",
        "    \n",
        "    if os.getenv(\"NUMERAI_MODEL_ID_REGRESSIONS\"):\n",
        "        print(\"Loaded Numerai Model ID into Global Environment!\")\n",
        "    else:\n",
        "        os.environ[\"NUMERAI_MODEL_ID_REGRESSIONS\"] = getpass(\"Please enter your Numerai Model ID. You can find your key here: https://numer.ai/submit -> \")\n",
        "\n",
        "credential()\n",
        "public_key = os.environ.get(\"NUMERAI_PUBLIC_KEY\")\n",
        "secret_key = os.environ.get(\"NUMERAI_SECRET_KEY\")\n",
        "model_id = os.environ.get(\"NUMERAI_MODEL_ID_REGRESSIONS\")\n",
        "napi = numerapi.NumerAPI(verbosity=\"info\", public_id=public_key, secret_key=secret_key)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Numerai Public Key into Global Environment!\n",
            "Loaded Numerai Secret Key into Global Environment!\n",
            "Loaded Numerai Model ID into Global Environment!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9mGss3CaIJ9"
      },
      "source": [
        "## Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7nD7Go-aJPF",
        "outputId": "afb90ea9-ecb4-4758-f1e1-eeb1e35bd922"
      },
      "source": [
        "napi.download_current_dataset()\n",
        "tourn_file = Path(f'./numerai_dataset_{napi.get_current_round()}/numerai_tournament_data.csv')\n",
        "train_file = Path(f'./numerai_dataset_{napi.get_current_round()}/numerai_training_data.csv')\n",
        "processed_train_file = Path('./training_processed.csv')\n",
        "\n",
        "if processed_train_file.exists():\n",
        "    print(\"Loading the processed training data from file\\n\")\n",
        "    training_data = pd.read_csv(processed_train_file)\n",
        "else:\n",
        "    tourn_iter_csv = pd.read_csv(tourn_file, iterator=True, chunksize=1e6)\n",
        "    val_df = pd.concat([chunk[chunk['data_type'] == 'validation'] for chunk in tqdm(tourn_iter_csv)])\n",
        "    tourn_iter_csv.close()\n",
        "    training_data = pd.read_csv(train_file)\n",
        "    training_data = pd.concat([training_data, val_df])\n",
        "    training_data.reset_index(drop=True, inplace=True)\n",
        "    print(\"Training Dataset Generated! Saving to file ...\")\n",
        "    training_data.to_csv(processed_train_file, index=False)\n",
        "\n",
        "\n",
        "feature_cols = training_data.columns[training_data.columns.str.startswith('feature')]\n",
        "target_cols = ['target']\n",
        "\n",
        "train_idx = training_data.index[training_data.data_type=='train'].tolist()\n",
        "val_idx = training_data.index[training_data.data_type=='validation'].tolist()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-13 16:38:51,496 INFO numerapi.base_api: target file already exists\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading the processed training data from file\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnRig23TaOGL"
      },
      "source": [
        "## Metrics Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o0rGS_FaPMz"
      },
      "source": [
        "def corr(df: pd.DataFrame) -> np.float32:\n",
        "    \"\"\"\n",
        "    Calculate the correlation by using grouped per-era data\n",
        "    :param df: A Pandas DataFrame containing the columns \"era\", \"target\" and \"prediction\"\n",
        "    :return: The average per-era correlations.\n",
        "    \"\"\"\n",
        "    def _score(sub_df: pd.DataFrame) -> np.float32:\n",
        "        \"\"\" Calculate Spearman correlation for Pandas' apply method \"\"\"\n",
        "        return spearmanr(sub_df[\"target\"],  sub_df[\"prediction\"])[0]\n",
        "    corrs = df.groupby(\"era\").apply(_score)\n",
        "    return corrs.mean() \n",
        "\n",
        "def sharpe(df: pd.DataFrame) -> np.float32:\n",
        "    \"\"\"\n",
        "    Calculate the Sharpe ratio by using grouped per-era data\n",
        "    :param df: A Pandas DataFrame containing the columns \"era\", \"target\" and \"prediction\"\n",
        "    :return: The Sharpe ratio for your predictions.\n",
        "    \"\"\"\n",
        "    def _score(sub_df: pd.DataFrame) -> np.float32:\n",
        "        \"\"\" Calculate Spearman correlation for Pandas' apply method \"\"\"\n",
        "        return spearmanr(sub_df[\"target\"],  sub_df[\"prediction\"])[0]\n",
        "    corrs = df.groupby(\"era\").apply(_score)\n",
        "    return corrs.mean() / corrs.std()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFwt8jJvaRWW"
      },
      "source": [
        "# Era \"Time Series\" Cross Validation\n",
        "\n",
        "The goal of this section is to set up a \"group time series\" approach where we specify a certain set of \"eras\" for training with the last era for validation. We will be training on segments of the validation set.\n",
        "\n",
        "There are a few ways to do this; I want to write a class that can take the \"eras to test on\" as input and return CV folds as outout. Perhaps a future refinement would include an argument for number of eras validate on. Perhaps unnecessary given that the \"real\" task is testing on a single era. Or four eras?\n",
        "\n",
        "## Usage\n",
        "\n",
        "1. Initialize the class with the eras column: `cv = EraCV(training_data.era)`\n",
        "2. Get splits: `X, y = test.get_splits(valid_start = 80, valid_n_eras = 4, train_n_eras = None)`\n",
        "\n",
        "The `valid_start` argument identifies the first training era; it takes an integer value. `valid_n_eras` is the number of eras to include in the validation set. `train_n_eras` is the number of eras to include in the training set. `train_n_eras` before `valid_start` are included in the training set. If no argument is passed to `train_n_eras`, all eras from 0 to `valid_start` are included.\n",
        "\n",
        "A single instance of this class can be used in a loop to generate multiple train/test splits. Assuming you want to keep the number of train and test eras constant, you can just iterate over a list of validation starting eras.\n",
        "\n",
        "Features such as checking if a given validation era actually exists have not yet been implemented."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOCjHXxiaaAp"
      },
      "source": [
        "class EraCV:\n",
        "    \"\"\"Select validation eras and train on previous eras\n",
        "\n",
        "    provides train/test indices to split data in train/test splits. In\n",
        "    each split, one or more eras are used as a validation set while the\n",
        "    specified number of immediately preceding eras are used as a\n",
        "    training set.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, eras):\n",
        "        self.eras = eras\n",
        "        self.unique_eras = self._era_to_int(eras.unique())\n",
        "        self.eras_int = self._era_to_int(eras)\n",
        "        #self.valid_start = valid_start\n",
        "        #self.valid_n_eras = valid_n_eras\n",
        "        #self.train_n_eras = 0 if (train_n_eras is None) else train_n_eras\n",
        "    \n",
        "    def _era_to_int(self, eras):\n",
        "        return [int(era[3:]) for era in eras]\n",
        "\n",
        "    def get_valid_indices(self, valid_start, valid_n_eras):\n",
        "        self.valid_eras = self.unique_eras[self.unique_eras.index(valid_start):\\\n",
        "                                      self.unique_eras.index(valid_start)+\\\n",
        "                                      valid_n_eras]\n",
        "        valid_bool = [era in self.valid_eras for era in self.eras_int] \n",
        "        self.valid_indices = np.where(valid_bool)\n",
        "\n",
        "    def get_train_indices(self, valid_start:int, train_n_eras:int):\n",
        "        train_n_eras = 0 if (train_n_eras is None) else train_n_eras\n",
        "        self.train_eras = [era for era in self.unique_eras if era <\\\n",
        "                           valid_start][-train_n_eras:]\n",
        "        train_bool = [era in self.train_eras for era in self.eras_int]\n",
        "        self.train_indices = np.where(train_bool)\n",
        "\n",
        "    def get_splits(self, valid_start:int, valid_n_eras:int,\n",
        "                   train_n_eras:int = None):\n",
        "        self.get_valid_indices(valid_start, valid_n_eras)\n",
        "        self.get_train_indices(valid_start, train_n_eras)\n",
        "        return self.train_indices[0], self.valid_indices[0]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO43hJqUac6z"
      },
      "source": [
        "# Linear Regression Demonstration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bimg_22oafVK",
        "outputId": "5d0aa36e-b0f7-4aa1-bcd2-702eec1347de"
      },
      "source": [
        "corrs = []\n",
        "sharpes = []\n",
        "era_split = EraCV(eras = training_data.era)\n",
        "X, y, era = training_data[feature_cols], training_data.target, training_data.era\n",
        "for valid_era in tqdm(range(200,209)):\n",
        "    train, test = era_split.get_splits(valid_start = valid_era,\n",
        "                           valid_n_eras = 4,\n",
        "                           train_n_eras = 50)\n",
        "    model = sklearn.linear_model.LinearRegression(n_jobs = -1)\n",
        "    model.fit(X.iloc[train], y.iloc[train])\n",
        "    val_preds = model.predict(X.iloc[test])\n",
        "    eval_df = pd.DataFrame({'prediction':val_preds,\n",
        "                        'target':y.iloc[test],\n",
        "                        'era':era.iloc[test]}).reset_index()\n",
        "    corrs.append(corr(eval_df))\n",
        "    sharpes.append(sharpe(eval_df))\n",
        "\n",
        "print(corrs)\n",
        "print(sharpes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [01:11<00:00,  7.99s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.007221323160113864, 0.019747589012373216, 0.014591688589274144, -0.002209343140336509, 0.003436434304452429, 0.0017170660155478596, 0.009927853627001944, 0.0175896213761404, 0.012326817375057541]\n",
            "[0.2880704062851405, 0.8254960106953122, 0.5365416338781753, -0.05678378916415171, 0.0903576886278792, 0.05125240876655709, 0.2972006561378662, 1.3761530359055556, 0.4027527038637555]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}