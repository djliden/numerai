{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "run_from_colab.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djliden/numerai/blob/main/run_from_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5E04YfM1EpE"
      },
      "source": [
        "# Run from Colab\n",
        "\n",
        "NB Goal: Set up a system for cloning this package and running the model(s) on colab in a fairly hands-off way.\n",
        "\n",
        "To authenticate, either upload your `.env` file with the necessary API keys to the numerai folder which you will clone below, or you will be prompted to copy the keys."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYIQMMmm1EpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657cd11c-bc18-4563-f7c9-e38e5a92eb4d"
      },
      "source": [
        "!git clone https://github.com/djliden/numerai.git\n",
        "%cd numerai"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'numerai'...\n",
            "remote: Enumerating objects: 180, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
            "remote: Total 180 (delta 90), reused 128 (delta 52), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (180/180), 139.19 KiB | 874.00 KiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n",
            "/content/numerai\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4mvfr4Z1Kx_"
      },
      "source": [
        "%%capture\n",
        "%%bash\n",
        "pip install --upgrade fastai numerapi python-dotenv ipywidgets jupyter ipython ipython-genutils yacs"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlKPARdb2O7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641909a2-cda5-4368-dbdf-bb0d43b75cd8"
      },
      "source": [
        "!python ./src/fastai_tabular.py ./src/config/experiments/expt_colab.yaml"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DATA:\n",
            "  BATCH_SIZE: 2048\n",
            "  REFRESH: False\n",
            "  SAVE_PROCESSED_TRAIN: True\n",
            "EVAL:\n",
            "  SAVE_PREDS: True\n",
            "  SUBMIT_PREDS: True\n",
            "MODEL:\n",
            "  BATCHNORM_FINAL: True\n",
            "  DROPOUT_P: [0, 0]\n",
            "  EMBED_DROPOUT_P: 0\n",
            "  GROUP: fastai_tabular\n",
            "  LAYERS: [400, 400]\n",
            "  NAME: submission_simple\n",
            "  USE_BATCHNORM: True\n",
            "  WEIGHT_DECAY: 0\n",
            "  Y_RANGE: [0, 1]\n",
            "RESULTS:\n",
            "  \n",
            "SESSION:\n",
            "  NAME: Default\n",
            "SYSTEM:\n",
            "  DEBUG: False\n",
            "  TIME: 2021_2_28_50\n",
            "TRAIN:\n",
            "  N_EPOCHS: 6\n",
            "Loaded Numerai Public Key into Global Environment!\n",
            "Loaded Numerai Secret Key into Global Environment!\n",
            "The dataset has already been downloaded.\n",
            "You can re-download it with refresh = True\n",
            "setting up fastai dataloaders\n",
            "Loading the processed training data from file\n",
            "\n",
            "tcmalloc: large alloc 1591296000 bytes == 0x559614b64000 @  0x7f58ff10b1e7 0x7f58fcc8b46e 0x7f58fccdbc7b 0x7f58fccdc35f 0x7f58fcd7e103 0x55954d9840e4 0x55954d983de0 0x55954d9f86f5 0x55954d98569a 0x55954d9f3a45 0x55954d9f2b0e 0x55954d98577a 0x55954d9f3a45 0x55954d98569a 0x55954d9f3a45 0x55954d98569a 0x55954d9f3a45 0x55954d9f2b0e 0x55954d98577a 0x55954d9f486a 0x55954d9f2e0d 0x55954d98577a 0x55954d9f486a 0x55954d9f2e0d 0x55954d98577a 0x55954d9f486a 0x55954d9f2b0e 0x55954d98602c 0x55954d9c6d39 0x55954d9c3c84 0x55954d9848e9\n",
            "tcmalloc: large alloc 1591296000 bytes == 0x55967479c000 @  0x7f58ff10b1e7 0x7f58fcc8b46e 0x7f58fccdbc7b 0x7f58fccdbd97 0x7f58fccd54a5 0x7f58fcd72eab 0x55954d984050 0x55954da7599d 0x55954d9f7fe9 0x55954d9f2b0e 0x55954d98602c 0x55954d986231 0x55954d9f51e6 0x55954d9f2e0d 0x55954d98577a 0x55954d9f486a 0x55954d9f2e0d 0x55954d98577a 0x55954d9f486a 0x55954d9f2b0e 0x55954d98577a 0x55954d9f7e50 0x55954d9f2e0d 0x55954d98602c 0x55954d9c6d39 0x55954d9c3c84 0x55954d9848e9 0x55954d9f8ade 0x55954d9f2b0e 0x55954d98577a 0x55954d9f486a\n",
            "setting up the fastai model\n",
            "training the model\n",
            "\n",
            "[N | train --------- | valid ----------- | corr ------------- | time]\n",
            "[0, 0.051119621843099594, 0.05108913034200668, 0.00896756694194165, '00:06']\n",
            "[1, 0.04988350346684456, 0.05038071051239967, 0.01659559505742811, '00:06']\n",
            "[2, 0.04982942342758179, 0.05048360675573349, 0.015383032813779037, '00:06']\n",
            "[3, 0.04914487153291702, 0.0505029633641243, 0.018686754707946913, '00:06']\n",
            "[4, 0.048255838453769684, 0.05099015682935715, 0.018196198268025886, '00:06']\n",
            "[5, 0.04717928543686867, 0.05104827508330345, 0.01853527818335153, '00:06']\n",
            "Making Predictions on Validation Set\n",
            "Model training has completed.\n",
            "Validation correlation: 0.019.\n",
            "validation sharpe: 0.869\n",
            "Generating and Saving Predictions\n",
            "Generating Predictions...\n",
            "\n",
            "Saving Predictions...\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"./src/fastai_tabular.py\", line 113, in <module>\n",
            "    predictions.save_predictions()\n",
            "  File \"/content/numerai/src/utils/eval.py\", line 65, in save_predictions\n",
            "    self.outpath.mkdir()\n",
            "  File \"/usr/lib/python3.7/pathlib.py\", line 1273, in mkdir\n",
            "    self._accessor.mkdir(self, mode)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '../output/predictions'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVLqFYL7EpKs"
      },
      "source": [
        "## Outstanding Issues:\n",
        "- Progress bars not rendering correctly.\n",
        "\n",
        "## Notes\n",
        "- Colab Pro does not seem to have improved training times relative to Colab, but I gues that could depend on which GPU I'm assigned based on overall usage...\n",
        "- Relatively small number of units per layer seems to be working best -- 400, 400 was good.\n",
        "- Using batchnorm: no apparent improvement in training times.\n",
        "    - With: .021 corr .808 sharpe\n",
        "    - Without: (marginally faster): .016 correlation .652 sharpe (notably, running same config locally, ended up with much higher results .023 and > 1)\n",
        "    - With + with final: even slower. .023 corr and 1.051 sharpe\n",
        "- 256, 256 layers\n",
        "    - Same time roughly\n",
        "    - .023 corr .917 sharpe\n",
        "- back to 400, increase y_range max to 1.2\n",
        "    - .021, .941 -- so pretty much the same.\n",
        "- dropout 0.5; embed_dropout 0.5, 20 epochs: .021, .722\n",
        "- 6 epochs, dropout .1: .023, .822\n",
        "    - dropout 0.2: .020, .758\n",
        "    - dropout 0.3: .021, .784\n",
        "- Bigger network: 1500, 1500, no dropout: .021, .848\n",
        "    - with embed dropout only 0.5 BUT this doesn't make sense because our vars are treated as continuous so must just be randomness.\n",
        "    - with embed [0.5, 0] to capture the intended effect: .021, .707.\n",
        "\n",
        "\n",
        "## Ideas\n",
        "- Option to add a new config at end -- \"if you would like to add a new config, please enter a path\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey4soGw-GEcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebfde8a8-92fc-4e76-c760-3bba31829268"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/27)\u001b[K\rremote: Counting objects:   7% (2/27)\u001b[K\rremote: Counting objects:  11% (3/27)\u001b[K\rremote: Counting objects:  14% (4/27)\u001b[K\rremote: Counting objects:  18% (5/27)\u001b[K\rremote: Counting objects:  22% (6/27)\u001b[K\rremote: Counting objects:  25% (7/27)\u001b[K\rremote: Counting objects:  29% (8/27)\u001b[K\rremote: Counting objects:  33% (9/27)\u001b[K\rremote: Counting objects:  37% (10/27)\u001b[K\rremote: Counting objects:  40% (11/27)\u001b[K\rremote: Counting objects:  44% (12/27)\u001b[K\rremote: Counting objects:  48% (13/27)\u001b[K\rremote: Counting objects:  51% (14/27)\u001b[K\rremote: Counting objects:  55% (15/27)\u001b[K\rremote: Counting objects:  59% (16/27)\u001b[K\rremote: Counting objects:  62% (17/27)\u001b[K\rremote: Counting objects:  66% (18/27)\u001b[K\rremote: Counting objects:  70% (19/27)\u001b[K\rremote: Counting objects:  74% (20/27)\u001b[K\rremote: Counting objects:  77% (21/27)\u001b[K\rremote: Counting objects:  81% (22/27)\u001b[K\rremote: Counting objects:  85% (23/27)\u001b[K\rremote: Counting objects:  88% (24/27)\u001b[K\rremote: Counting objects:  92% (25/27)\u001b[K\rremote: Counting objects:  96% (26/27)\u001b[K\rremote: Counting objects: 100% (27/27)\u001b[K\rremote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects:   9% (1/11)\u001b[K\rremote: Compressing objects:  18% (2/11)\u001b[K\rremote: Compressing objects:  27% (3/11)\u001b[K\rremote: Compressing objects:  36% (4/11)\u001b[K\rremote: Compressing objects:  45% (5/11)\u001b[K\rremote: Compressing objects:  54% (6/11)\u001b[K\rremote: Compressing objects:  63% (7/11)\u001b[K\rremote: Compressing objects:  72% (8/11)\u001b[K\rremote: Compressing objects:  81% (9/11)\u001b[K\rremote: Compressing objects:  90% (10/11)\u001b[K\rremote: Compressing objects: 100% (11/11)\u001b[K\rremote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 19 (delta 11), reused 13 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects:   5% (1/19)   \rUnpacking objects:  10% (2/19)   \rUnpacking objects:  15% (3/19)   \rUnpacking objects:  21% (4/19)   \rUnpacking objects:  26% (5/19)   \rUnpacking objects:  31% (6/19)   \rUnpacking objects:  36% (7/19)   \rUnpacking objects:  42% (8/19)   \rUnpacking objects:  47% (9/19)   \rUnpacking objects:  52% (10/19)   \rUnpacking objects:  57% (11/19)   \rUnpacking objects:  63% (12/19)   \rUnpacking objects:  68% (13/19)   \rUnpacking objects:  73% (14/19)   \rUnpacking objects:  78% (15/19)   \rUnpacking objects:  84% (16/19)   \rUnpacking objects:  89% (17/19)   \rUnpacking objects:  94% (18/19)   \rUnpacking objects: 100% (19/19)   \rUnpacking objects: 100% (19/19), done.\n",
            "From https://github.com/djliden/numerai\n",
            "   73676ba..b9dabd8  main       -> origin/main\n",
            "Updating 73676ba..b9dabd8\n",
            "Fast-forward\n",
            " run_from_colab.ipynb   | 107 \u001b[32m+++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m------\u001b[m\n",
            " src/config/config.py   |   2 \u001b[32m+\u001b[m\n",
            " src/fastai_tabular.py  |  10 \u001b[32m+++\u001b[m\u001b[31m--\u001b[m\n",
            " src/utils/prep_data.py |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 4 files changed, 105 insertions(+), 18 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y22Is4_7bDqC"
      },
      "source": [
        "!zip -r /logs.zip /content/numerai/output/logs/*\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}