{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/djliden/numerai/blob/main/run_from_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5E04YfM1EpE"
   },
   "source": [
    "# Run from Colab\n",
    "\n",
    "NB Goal: Set up a system for cloning this package and running the model(s) on colab in a fairly hands-off way.\n",
    "\n",
    "To authenticate, either upload your `.env` file with the necessary API keys to the numerai folder which you will clone below, or you will be prompted to copy the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYIQMMmm1EpI",
    "outputId": "657cd11c-bc18-4563-f7c9-e38e5a92eb4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'numerai'...\n",
      "remote: Enumerating objects: 383, done.\u001b[K\n",
      "remote: Counting objects: 100% (383/383), done.\u001b[K\n",
      "remote: Compressing objects: 100% (285/285), done.\u001b[K\n",
      "remote: Total 383 (delta 226), reused 207 (delta 89), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (383/383), 233.26 KiB | 1.20 MiB/s, done.\n",
      "Resolving deltas: 100% (226/226), done.\n",
      "/home/djliden91/git/projects/numerai/numerai\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/djliden/numerai.git\n",
    "%cd numerai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S4mvfr4Z1Kx_"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "pip install --upgrade fastai numerapi python-dotenv ipywidgets jupyter ipython ipython-genutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlKPARdb2O7q",
    "outputId": "641909a2-cda5-4368-dbdf-bb0d43b75cd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV:\n",
      "  GAP: 0\n",
      "  TRAIN_START: 0\n",
      "  TRAIN_STOP: null\n",
      "  VAL_END: 210\n",
      "  VAL_N_ERAS: 4\n",
      "  VAL_START: 206\n",
      "DATA:\n",
      "  REFRESH: false\n",
      "  SAVE_PROCESSED_TRAIN: true\n",
      "EVAL:\n",
      "  CHUNK_SIZE: 1000000\n",
      "  SAVE_PREDS: true\n",
      "  SUBMIT_PREDS: true\n",
      "MODEL:\n",
      "  BATCHNORM_FINAL: true\n",
      "  BATCH_SIZE: 2048\n",
      "  DROPOUT_P: 0.05\n",
      "  EMBED_DROPOUT_P: 0\n",
      "  GROUP: fastai_tabular\n",
      "  LAYERS:\n",
      "  - 400\n",
      "  - 400\n",
      "  LEARNING_RATE: 0.001\n",
      "  LOSS_FUNCTION: MSELossFlat\n",
      "  METRICS:\n",
      "  - SpearmanCorrCoef\n",
      "  NAME: subattempt\n",
      "  N_EPOCHS: 6\n",
      "  TYPE: fastai_tabular\n",
      "  USE_BATCHNORM: true\n",
      "  WEIGHT_DECAY: 0\n",
      "  Y_RANGE:\n",
      "  - 0\n",
      "  - 1.1\n",
      "SYSTEM:\n",
      "  DEBUG: false\n",
      "  TIME: '2021_4_3_756'\n",
      "TRAIN:\n",
      "  N_EPOCHS: 6\n",
      "\n",
      "Loaded Numerai Public Key into Global Environment!\n",
      "Loaded Numerai Secret Key into Global Environment!\n",
      "The dataset has already been downloaded.\n",
      "You can re-download it with refresh = True\n",
      "Loading the pickled training data from file\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]training the model\n",
      "\n",
      "[N | train --------- | valid ----------- | corr ------------- | time]\n",
      "[0, 0.08181564509868622, 0.05984537675976753, 0.011278129596455877, '00:36']\n"
     ]
    }
   ],
   "source": [
    "!python ./src/exec_config.py \"fastai_tabular\" ./src/config/experiments/expt_2.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVLqFYL7EpKs"
   },
   "source": [
    "## Outstanding Issues:\n",
    "- Progress bars not rendering correctly.\n",
    "\n",
    "## Notes\n",
    "- Colab Pro does not seem to have improved training times relative to Colab, but I gues that could depend on which GPU I'm assigned based on overall usage...\n",
    "- Relatively small number of units per layer seems to be working best -- 400, 400 was good.\n",
    "- Using batchnorm: no apparent improvement in training times.\n",
    "    - With: .021 corr .808 sharpe\n",
    "    - Without: (marginally faster): .016 correlation .652 sharpe (notably, running same config locally, ended up with much higher results .023 and > 1)\n",
    "    - With + with final: even slower. .023 corr and 1.051 sharpe\n",
    "- 256, 256 layers\n",
    "    - Same time roughly\n",
    "    - .023 corr .917 sharpe\n",
    "- back to 400, increase y_range max to 1.2\n",
    "    - .021, .941 -- so pretty much the same.\n",
    "- dropout 0.5; embed_dropout 0.5, 20 epochs: .021, .722\n",
    "- 6 epochs, dropout .1: .023, .822\n",
    "    - dropout 0.2: .020, .758\n",
    "    - dropout 0.3: .021, .784\n",
    "- Bigger network: 1500, 1500, no dropout: .021, .848\n",
    "    - with embed dropout only 0.5 BUT this doesn't make sense because our vars are treated as continuous so must just be randomness.\n",
    "    - with embed [0.5, 0] to capture the intended effect: .021, .707.\n",
    "\n",
    "\n",
    "## Ideas\n",
    "- Option to add a new config at end -- \"if you would like to add a new config, please enter a path\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ey4soGw-GEcP",
    "outputId": "ebfde8a8-92fc-4e76-c760-3bba31829268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 27, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 19 (delta 11), reused 13 (delta 8), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (19/19), done.\n",
      "From https://github.com/djliden/numerai\n",
      "   73676ba..b9dabd8  main       -> origin/main\n",
      "Updating 73676ba..b9dabd8\n",
      "Fast-forward\n",
      " run_from_colab.ipynb   | 107 \u001b[32m+++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m------\u001b[m\n",
      " src/config/config.py   |   2 \u001b[32m+\u001b[m\n",
      " src/fastai_tabular.py  |  10 \u001b[32m+++\u001b[m\u001b[31m--\u001b[m\n",
      " src/utils/prep_data.py |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
      " 4 files changed, 105 insertions(+), 18 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y22Is4_7bDqC"
   },
   "outputs": [],
   "source": [
    "!zip -r /logs.zip /content/numerai/output/logs/*\n",
    "from google.colab import files\n",
    "files.download(\"/content/file.zip\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "run_from_colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "numerai",
   "language": "python",
   "name": "numerai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
