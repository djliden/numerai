{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "run_from_colab.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djliden/numerai/blob/main/run_from_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5E04YfM1EpE"
      },
      "source": [
        "# Run from Colab\n",
        "\n",
        "NB Goal: Set up a system for cloning this package and running the model(s) on colab in a fairly hands-off way.\n",
        "\n",
        "To authenticate, either upload your `.env` file with the necessary API keys to the numerai folder which you will clone below, or you will be prompted to copy the keys."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYIQMMmm1EpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657cd11c-bc18-4563-f7c9-e38e5a92eb4d"
      },
      "source": [
        "!git clone https://github.com/djliden/numerai.git\n",
        "%cd numerai"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'numerai'...\n",
            "remote: Enumerating objects: 180, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
            "remote: Total 180 (delta 90), reused 128 (delta 52), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (180/180), 139.19 KiB | 874.00 KiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n",
            "/content/numerai\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4mvfr4Z1Kx_"
      },
      "source": [
        "%%capture\n",
        "%%bash\n",
        "pip install --upgrade fastai numerapi python-dotenv ipywidgets jupyter ipython ipython-genutils yacs"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlKPARdb2O7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "709550f4-9eb9-4472-8558-2f8577674ed0"
      },
      "source": [
        "!python ./src/fastai_tabular.py ./src/config/experiments/expt_colab.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DATA:\n",
            "  REFRESH: False\n",
            "  SAVE_PROCESSED_TRAIN: True\n",
            "EVAL:\n",
            "  SAVE_PREDS: False\n",
            "MODEL:\n",
            "  BATCHNORM_FINAL: True\n",
            "  DROPOUT_P: [0.5, 0]\n",
            "  EMBED_DROPOUT_P: 0\n",
            "  GROUP: fastai_tabular\n",
            "  LAYERS: [1500, 1500]\n",
            "  NAME: layers_1500s_embed\n",
            "  USE_BATCHNORM: True\n",
            "  WEIGHT_DECAY: 0\n",
            "  Y_RANGE: [0, 1]\n",
            "RESULTS:\n",
            "  \n",
            "SESSION:\n",
            "  NAME: Default\n",
            "SYSTEM:\n",
            "  DEBUG: False\n",
            "  TIME: 2021_2_28_432\n",
            "TRAIN:\n",
            "  N_EPOCHS: 6\n",
            "Loaded Numerai Public Key into Global Environment!\n",
            "Loaded Numerai Secret Key into Global Environment!\n",
            "The dataset has already been downloaded.\n",
            "You can re-download it with refresh = True\n",
            "setting up fastai dataloaders\n",
            "Loading the processed training data from file\n",
            "\n",
            "tcmalloc: large alloc 1591296000 bytes == 0x55c72821a000 @  0x7f1375ec91e7 0x7f1373a4946e 0x7f1373a99c7b 0x7f1373a9a35f 0x7f1373b3c103 0x55c6616ab0e4 0x55c6616aade0 0x55c66171f6f5 0x55c6616ac69a 0x55c66171aa45 0x55c661719b0e 0x55c6616ac77a 0x55c66171aa45 0x55c6616ac69a 0x55c66171aa45 0x55c6616ac69a 0x55c66171aa45 0x55c661719b0e 0x55c6616ac77a 0x55c66171b86a 0x55c661719e0d 0x55c6616ac77a 0x55c66171b86a 0x55c661719e0d 0x55c6616ac77a 0x55c66171b86a 0x55c661719b0e 0x55c6616ad02c 0x55c6616edd39 0x55c6616eac84 0x55c6616ab8e9\n",
            "tcmalloc: large alloc 1591296000 bytes == 0x55c787e52000 @  0x7f1375ec91e7 0x7f1373a4946e 0x7f1373a99c7b 0x7f1373a99d97 0x7f1373a934a5 0x7f1373b30eab 0x55c6616ab050 0x55c66179c99d 0x55c66171efe9 0x55c661719b0e 0x55c6616ad02c 0x55c6616ad231 0x55c66171c1e6 0x55c661719e0d 0x55c6616ac77a 0x55c66171b86a 0x55c661719e0d 0x55c6616ac77a 0x55c66171b86a 0x55c661719b0e 0x55c6616ac77a 0x55c66171ee50 0x55c661719e0d 0x55c6616ad02c 0x55c6616edd39 0x55c6616eac84 0x55c6616ab8e9 0x55c66171fade 0x55c661719b0e 0x55c6616ac77a 0x55c66171b86a\n",
            "setting up the fastai model\n",
            "training the model\n",
            "\n",
            "[N | train --------- | valid ----------- | corr ------------- | time]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVLqFYL7EpKs"
      },
      "source": [
        "## Outstanding Issues:\n",
        "- Progress bars not rendering correctly.\n",
        "\n",
        "## Notes\n",
        "- Colab Pro does not seem to have improved training times relative to Colab, but I gues that could depend on which GPU I'm assigned based on overall usage...\n",
        "- Relatively small number of units per layer seems to be working best -- 400, 400 was good.\n",
        "- Using batchnorm: no apparent improvement in training times.\n",
        "    - With: .021 corr .808 sharpe\n",
        "    - Without: (marginally faster): .016 correlation .652 sharpe (notably, running same config locally, ended up with much higher results .023 and > 1)\n",
        "    - With + with final: even slower. .023 corr and 1.051 sharpe\n",
        "- 256, 256 layers\n",
        "    - Same time roughly\n",
        "    - .023 corr .917 sharpe\n",
        "- back to 400, increase y_range max to 1.2\n",
        "    - .021, .941 -- so pretty much the same.\n",
        "- dropout 0.5; embed_dropout 0.5, 20 epochs: .021, .722\n",
        "- 6 epochs, dropout .1: .023, .822\n",
        "    - dropout 0.2: .020, .758\n",
        "    - dropout 0.3: .021, .784\n",
        "- Bigger network: 1500, 1500, no dropout: .021, .848\n",
        "    - with embed dropout only 0.5 BUT this doesn't make sense because our vars are treated as continuous so must just be randomness.\n",
        "    - with embed [0.5, 0] to capture the intended effect\n",
        "\n",
        "\n",
        "## Ideas\n",
        "- Option to add a new config at end -- \"if you would like to add a new config, please enter a path\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6oQ8G1G6HYm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey4soGw-GEcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3493ff00-2fb6-418e-f14d-cca93f6f8faf"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects:   9% (1/11)\u001b[K\rremote: Counting objects:  18% (2/11)\u001b[K\rremote: Counting objects:  27% (3/11)\u001b[K\rremote: Counting objects:  36% (4/11)\u001b[K\rremote: Counting objects:  45% (5/11)\u001b[K\rremote: Counting objects:  54% (6/11)\u001b[K\rremote: Counting objects:  63% (7/11)\u001b[K\rremote: Counting objects:  72% (8/11)\u001b[K\rremote: Counting objects:  81% (9/11)\u001b[K\rremote: Counting objects:  90% (10/11)\u001b[K\rremote: Counting objects: 100% (11/11)\u001b[K\rremote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects:  25% (1/4)\u001b[K\rremote: Compressing objects:  50% (2/4)\u001b[K\rremote: Compressing objects:  75% (3/4)\u001b[K\rremote: Compressing objects: 100% (4/4)\u001b[K\rremote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 7 (delta 5), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  14% (1/7)   \rUnpacking objects:  28% (2/7)   \rUnpacking objects:  42% (3/7)   \rUnpacking objects:  57% (4/7)   \rUnpacking objects:  71% (5/7)   \rUnpacking objects:  85% (6/7)   \rUnpacking objects: 100% (7/7)   \rUnpacking objects: 100% (7/7), done.\n",
            "From https://github.com/djliden/numerai\n",
            "   02a45ed..73676ba  main       -> origin/main\n",
            "Updating 02a45ed..73676ba\n",
            "Fast-forward\n",
            " run_from_colab.ipynb  | 90 \u001b[32m+++++++++++++++++++++++\u001b[m\u001b[31m----------------------------\u001b[m\n",
            " src/fastai_tabular.py |  3 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 42 insertions(+), 51 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y22Is4_7bDqC"
      },
      "source": [
        "!zip -r /logs.zip /content/numerai/output/logs/*\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}