{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surrounded-participation",
   "metadata": {},
   "source": [
    "# TO-DO\n",
    "1. (DONE) Make config updates recursive. Currently nested dicts are just overwriting. That is, if two config files have a MODEL keyword, the whole model is being overwritten.\n",
    "2. switch model to `**kwargs`-based setup so we can list all possibly-relevant ones.\n",
    "3. more-efficient CSV processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "empirical-barcelona",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f1193ae72105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path(__file__).parent)\n",
    "    \n",
    "    \n",
    "!pip install git+https://github.com/djliden/config-nest.git\n",
    "\n",
    "    \n",
    "    \n",
    "import confignest.confignest\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from importlib import import_module\n",
    "\n",
    "import src.utils.setup\n",
    "import src.utils.cross_val\n",
    "import src.utils.eval\n",
    "import src.utils.metrics\n",
    "import gc\n",
    "np.random.seed(623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cognitive-winner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV:\n",
      "  GAP: 0\n",
      "  TRAIN_START: 0\n",
      "  TRAIN_STOP: null\n",
      "  VAL_END: 210\n",
      "  VAL_N_ERAS: 3\n",
      "  VAL_START: 208\n",
      "DATA:\n",
      "  REFRESH: false\n",
      "  SAVE_PROCESSED_TRAIN: true\n",
      "EVAL:\n",
      "  CHUNK_SIZE: 1000000\n",
      "  SAVE_PREDS: false\n",
      "  SUBMIT_PREDS: false\n",
      "MODEL:\n",
      "  BATCHNORM_FINAL: true\n",
      "  BATCH_SIZE: 2048\n",
      "  DROPOUT_P: 0\n",
      "  LAYERS:\n",
      "  - 400\n",
      "  - 400\n",
      "  LEARNING_RATE: 0.001\n",
      "  LOSS_FUNCTION: MSELossFlat\n",
      "  METRICS:\n",
      "  - SpearmanCorrCoef\n",
      "  NAME: Unnamed\n",
      "  N_EPOCHS: 1\n",
      "  TYPE: fastai_tabular\n",
      "  USE_BATCHNORM: true\n",
      "  WEIGHT_DECAY: 0\n",
      "  Y_RANGE:\n",
      "  - 0\n",
      "  - 1\n",
      "SYSTEM:\n",
      "  DEBUG: false\n",
      "  TIME: '2021_4_3_823'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = \"fastai_tabular\"\n",
    "configpath = \"./src/config/experiments/config_debug.yaml\"\n",
    "default_config = Path(\"./src/config/default_config.yaml\")\n",
    "cfg = Config(default_config)\n",
    "model_cfg = Path(f'./src/models/default_configs/{model}.yaml')\n",
    "model_cls = model.title().replace(\"_\",\"\")\n",
    "cfg.update_config(model_cfg)\n",
    "cfg.update_config(configpath)\n",
    "ct = time.localtime()\n",
    "current_time = f'{ct[0]}_{ct[1]}_{ct[2]}_{ct[3]}{ct[4]}'\n",
    "cfg.update_config({'SYSTEM':{'TIME':current_time}})\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lined-viking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Numerai Public Key into Global Environment!\n",
      "Loaded Numerai Secret Key into Global Environment!\n"
     ]
    }
   ],
   "source": [
    "credential()\n",
    "napi = init_numerapi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "composite-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define key paths\n",
    "round = napi.get_current_round()\n",
    "#current_file = Path(data_dir/f\"numerai_dataset_{round}.zip\")\n",
    "train = Path(f\"./input/numerai_dataset_{round}/numerai_training_data.csv\")\n",
    "tourn = Path(f\"./input/numerai_dataset_{round}/numerai_tournament_data.csv\")\n",
    "processed = Path('./input/training_processed.csv')\n",
    "processed_pkl = Path('./input/training_processed.pkl')\n",
    "output = Path(\"./output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "structural-platform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has already been downloaded.\n",
      "You can re-download it with refresh = True\n",
      "Loading the pickled training data from file\n",
      "\n",
      "CPU times: user 127 ms, sys: 1.53 s, total: 1.66 s\n",
      "Wall time: 3.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "download_current(napi=napi)\n",
    "training_data, feature_cols, target_cols = process_current(processed,\n",
    "                                                           processed_pkl, train, tourn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-naples",
   "metadata": {},
   "source": [
    "time with float16: 1 min 28 s\n",
    "Time with float32: 1 min 12 s\n",
    "time with default: 1 min 32 s\n",
    "time with dask: 56.2 s\n",
    "time with dask and read train csv with dask: 1.16 s\n",
    "time deferring compute to after whole concat done: 52.9 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "warming-projection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCHNORM_FINAL: true\n",
      "BATCH_SIZE: 2048\n",
      "DROPOUT_P: 0\n",
      "LAYERS:\n",
      "- 400\n",
      "- 400\n",
      "LEARNING_RATE: 0.001\n",
      "LOSS_FUNCTION: MSELossFlat\n",
      "METRICS:\n",
      "- SpearmanCorrCoef\n",
      "NAME: Unnamed\n",
      "N_EPOCHS: 1\n",
      "TYPE: fastai_tabular\n",
      "USE_BATCHNORM: true\n",
      "WEIGHT_DECAY: 0\n",
      "Y_RANGE:\n",
      "- 0\n",
      "- 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FastaiTabular'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cfg.MODEL)\n",
    "model_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "persistent-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "modmod = import_module(f'src.models.{model}')\n",
    "mod = getattr(modmod, model_cls)(**cfg.MODEL.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "offensive-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "era_split = EraCV(eras = training_data.era)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continent-enlargement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EraCV(last era:212)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "era_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "smart-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = era_split.get_splits(valid_start = 209,\n",
    "                                           valid_n_eras = cfg.CV.VAL_N_ERAS,\n",
    "                                           train_start = cfg.CV.TRAIN_START,\n",
    "                                           train_stop = cfg.CV.TRAIN_STOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "european-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.dls = mod.build_data_loaders(df = training_data, cont_names = list(feature_cols),\n",
    "          train_idx = list(train_idx), val_idx = list(test_idx))\n",
    "mod.init_learner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "legendary-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print(mod.learner.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "enormous-wellington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model\n",
      "\n",
      "[N | train --------- | valid ----------- | corr ------------- | time]\n",
      "[0, 0.05665916949510574, 0.054120611399412155, 0.004433362185388489, '00:37']\n"
     ]
    }
   ],
   "source": [
    "mod.fit(df = training_data, cont_names = list(feature_cols),\n",
    "          train_idx = list(train_idx), val_idx = list(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "widespread-marathon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4429707313231095\n",
      "0.004436122191511287\n"
     ]
    }
   ],
   "source": [
    "val_preds = mod.predict(training_data.iloc[test_idx])\n",
    "\n",
    "prediction = val_preds\n",
    "target = list(training_data.target.iloc[test_idx])\n",
    "val_era = list(training_data.era[test_idx])\n",
    "eval_df = pd.DataFrame({'prediction':prediction,\n",
    "                        'target':target, 'era':val_era})\n",
    "eval_df\n",
    "print(sharpe(eval_df))\n",
    "print(val_corr(eval_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "editorial-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# might be necessary\n",
    "print(\"training the model\\n\")\n",
    "print((\"[N | train --------- | valid ----------- |\"\n",
    "       \" corr ------------- | time]\"))\n",
    "start = time.time()\n",
    "with learn.no_bar():\n",
    "    learn.fit_one_cycle(n_epoch = cfg.TRAIN.N_EPOCHS,\n",
    "                        wd = cfg.MODEL.WEIGHT_DECAY)\n",
    "end = time. time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "conventional-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_preds(model=mod, chunksize=5e5,\n",
    "           pred_path = output/\"preds.csv\",\n",
    "           feature_cols = feature_cols, tourn_path=tourn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numerai",
   "language": "python",
   "name": "numerai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
